{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OCSVM_try_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saugatabose28/Google-Colab-Work/blob/master/OCSVM_try_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KuTl1VnNfsX"
      },
      "source": [
        "!pip install transformers==3.0.0\n",
        "!pip install emoji\n",
        "!pip install onnx onnxruntime\n",
        "!pip install scikit-plot\n",
        "!pip install plot-metric\n",
        "!pip install pyod\n",
        "!pip install transformers[onnx]\n",
        "import tensorflow as tf\n",
        "import gc\n",
        "#import os\n",
        "import emoji as emoji\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from numpy import dstack\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy.linalg import norm\n",
        "from transformers import AutoModel\n",
        "from transformers import BertModel, BertTokenizer\n",
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "from pyod.models.ocsvm import OCSVM\n",
        "from pyod.utils.example import visualize#generate dataset\n",
        "data_path=\"drive/My Drive/Colab Notebooks\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "    \n",
        "    def __init__(self, bert):\n",
        "        super(BERT_Arch, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.lstm = nn.LSTM(768, 128,2,batch_first=True,bidirectional=True)\n",
        "        self.fc = nn.Linear(128*2, 2) \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "          sequence_output, pooled_output = self.bert(ids,attention_mask=mask)          \n",
        "          lstm_output, (h,c) = self.lstm(sequence_output) ## extract the 1st token's embeddings\n",
        "\n",
        "          hidden = torch.cat((lstm_output[:,-1, :128],lstm_output[:,0, 128:]),dim=-1)\n",
        "          hidden=hidden.view(-1,128*2)\n",
        "          weights1= (self.fc.weight)\n",
        "          weights=torch.transpose(weights1, 0, 1)\n",
        "          biases= (self.fc.bias)\n",
        "          r=2/torch.linalg.norm(weights1)\n",
        "          output=torch.matmul(hidden,weights)+biases\n",
        "          prediction= self.sigmoid(output)\n",
        "\n",
        "          return lstm_output, prediction,weights1,biases,r,output\n",
        "\n",
        "def read_dataset():\n",
        "    data = pd.read_csv(f\"{data_path}/preProcessedDavidson_90Hate.csv\")\n",
        "    return data['tweet'].tolist(), data['class']\n",
        "\n",
        "\n",
        "def data_process(data, labels):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    for sentence in data:\n",
        "        bert_inp = bert_tokenizer.__call__(sentence, max_length=12,\n",
        "                                           padding='max_length', pad_to_max_length=True,\n",
        "                                           truncation=True, return_token_type_ids=False)\n",
        "\n",
        "        input_ids.append(bert_inp['input_ids'])\n",
        "        attention_masks.append(bert_inp['attention_mask'])\n",
        "\n",
        "    input_ids = np.asarray(input_ids)\n",
        "    attention_masks = np.array(attention_masks)\n",
        "    labels = np.array(labels)\n",
        "    d=np.array(data)\n",
        "    return input_ids, attention_masks, labels,d\n",
        "\n",
        "\n",
        "def load_and_process():\n",
        "    data, labels = read_dataset()\n",
        "    num_of_labels = len(labels.unique())\n",
        "    #input_ids, attention_masks, labels = data_process(pre_process_dataset(data), labels)\n",
        "    input_ids, attention_masks, labels,d = data_process(data, labels)\n",
        "\n",
        "    return input_ids, attention_masks, labels,d\n",
        "\n",
        "\n",
        "# function to train the model\n",
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save model predictions\n",
        "    \n",
        "    #train_preds = []\n",
        "    # iterate over batches\n",
        "    total = len(train_dataloader)\n",
        "    correct=0\n",
        "    #print(total)\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        step = i+1\n",
        "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
        "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
        "        filledLength = int(100 * step // total)\n",
        "        bar = '█' * filledLength + '>'  *(filledLength < 100) + '.' * (99 - filledLength)\n",
        "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={total_accuracy}', end='')\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [b.to(device) for b in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        del batch\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "        #print((sent_id.size()))\n",
        "        ####for NLLL,hinge loss,multi####\n",
        "        lstm_output,prediction,weights,biases,r,output = model(sent_id, mask)\n",
        "        #print(labels.size())\n",
        "        #print(prediction.size())\n",
        "        #print(labels.size())\n",
        "        #print(prediction.size())\n",
        "                \n",
        "        #########Custom loss\n",
        "        loss = OCSVM_loss(weights,biases,lstm_output,output,r)\n",
        "        #print(loss)\n",
        "        print(\" training loss %f\" %loss.item())\n",
        "        #####################\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss += float(loss.item())\n",
        "        \n",
        " \n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        #total_preds.append(prediction)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step() \n",
        "   \n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / (len(train_dataloader)*batch_size)\n",
        "\n",
        "    accu=100.*correct/total\n",
        "    \n",
        "    ##for NLL, hinge,multimargin loss only##\n",
        "    #total_preds = np.concatenate(total_preds, axis=0)\n",
        "    ##\n",
        "\n",
        "    # returns the loss and predictions\n",
        "    ##for NLL, hinge,multimargin##\n",
        "    return avg_loss\n",
        "\n",
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "    print(\"\\n\\nEvaluating...\")\n",
        "\n",
        "    # deactivate dropout layers\n",
        "    model.eval()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save the model predictions\n",
        "    #total_preds = []\n",
        "    val_preds = []\n",
        "\n",
        "    # iterate over batches\n",
        "    total = len(val_dataloader)\n",
        "    correct=0\n",
        "    for i, batch in enumerate(val_dataloader):\n",
        "        \n",
        "        step = i+1\n",
        "        percent = \"{0:.2f}\".format(100 * (step / float(total)))\n",
        "        lossp = \"{0:.2f}\".format(total_loss/(total*batch_size))\n",
        "        filledLength = int(100 * step // total)\n",
        "        bar = '█' * filledLength + '>' * (filledLength < 100) + '.' * (99 - filledLength)\n",
        "        print(f'\\rBatch {step}/{total} |{bar}| {percent}% complete, loss={lossp}, accuracy={total_accuracy}', end='')\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [t.to(device) for t in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "        del batch\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # model predictions\n",
        "            ##for NLL, hinge,multimargin loss##\n",
        "            lstm_output,prediction,weights,biases,r,output = model(sent_id, mask)\n",
        "            #correct += prediction.eq(labels).sum().item()\n",
        "            loss = OCSVM_loss(weights,biases,lstm_output,output,r)\n",
        "            print(\" validation loss %f\" %loss.item())\n",
        "            #########\n",
        "\n",
        "            total_loss += float(loss.item())\n",
        "            #total_preds.append(prediction)\n",
        "            #val_preds.append(prediction)\n",
        "    \n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / (len(val_dataloader)*batch_size)\n",
        "\n",
        "    return avg_loss\n",
        "\n",
        "def OCSVM_loss(weight,bias,lstmOutput,output,r):\n",
        "\n",
        "    a=0.5*torch.square(torch.linalg.norm((weight)))\n",
        "    z = torch.zeros_like((bias))\n",
        "    b=torch.mean(torch.maximum(z,r-output))\n",
        "    l2 = a+(1/(0.01))*b-r\n",
        "    return l2\n",
        "\n",
        "\n",
        "# Specify the GPU\n",
        "# Setting up the device for GPU usage\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Load Data-set ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "input_ids, attention_masks, labels,text = load_and_process()\n",
        "df = pd.DataFrame(list(zip(input_ids, attention_masks)), columns=['input_ids', 'attention_masks'])\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ class distribution ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "# class = class label for majority of CF users. 0 - hate speech 1 - offensive language 2 - neither\n",
        "# ~~~~~~~~~~ Split train data-set into train, validation and test sets  ~~~~~~~~~~#\n",
        "train_text, val_text, train_labels, val_labels = train_test_split(df, labels,\n",
        "                            random_state=2018, test_size=0.2, stratify=labels)\n",
        "\n",
        "#del temp_text\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~ Import BERT Model and BERT Tokenizer ~~~~~~~~~~~~~~~~~~~~~#\n",
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Tokenization ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "# for train set\n",
        "train_seq = torch.tensor(df['input_ids'].tolist())\n",
        "train_mask = torch.tensor(df['attention_masks'].tolist())\n",
        "train_y = torch.tensor(labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(val_text['input_ids'].tolist())\n",
        "val_mask = torch.tensor(val_text['attention_masks'].tolist())\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Create DataLoaders ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "# define a batch size\n",
        "batch_size = 36\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Freeze BERT Parameters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "# push the model to GPU\n",
        "model = model.to(device)\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "epochs = 6\n",
        "current = 1\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "#global co\n",
        "while current <= epochs:\n",
        "\n",
        "    print(f'\\nEpoch {current} / {epochs}:')\n",
        "\n",
        "    # train model\n",
        "    \n",
        "    train_loss= train()\n",
        "    # evaluate model\n",
        "    \n",
        "    valid_loss= evaluate()\n",
        "\n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        #torch.save(model.state_dict(), 'saved_weights.pth')\n",
        "\n",
        "        # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "\n",
        "    print(f'\\n\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "    current = current + 1"
      ],
      "metadata": {
        "id": "uLCNVWxZmpjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb7e1e88-fbaa-485e-ca7b-e83612ddd79f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 / 6:\n",
            "Batch 1/40 |██>.................................................................................................| 2.50% complete, loss=0.00, accuracy=0 training loss 249.093842\n",
            "Batch 2/40 |█████>..............................................................................................| 5.00% complete, loss=0.17, accuracy=0 training loss 246.053497\n",
            "Batch 3/40 |███████>............................................................................................| 7.50% complete, loss=0.34, accuracy=0 training loss 243.587662\n",
            "Batch 4/40 |██████████>.........................................................................................| 10.00% complete, loss=0.51, accuracy=0 training loss 240.535110\n",
            "Batch 5/40 |████████████>.......................................................................................| 12.50% complete, loss=0.68, accuracy=0 training loss 235.940964\n",
            "Batch 6/40 |███████████████>....................................................................................| 15.00% complete, loss=0.84, accuracy=0 training loss 231.794464\n",
            "Batch 7/40 |█████████████████>..................................................................................| 17.50% complete, loss=1.00, accuracy=0 training loss 228.923462\n",
            "Batch 8/40 |████████████████████>...............................................................................| 20.00% complete, loss=1.16, accuracy=0 training loss 223.780914\n",
            "Batch 9/40 |██████████████████████>.............................................................................| 22.50% complete, loss=1.32, accuracy=0 training loss 219.547989\n",
            "Batch 10/40 |█████████████████████████>..........................................................................| 25.00% complete, loss=1.47, accuracy=0 training loss 215.266541\n",
            "Batch 11/40 |███████████████████████████>........................................................................| 27.50% complete, loss=1.62, accuracy=0 training loss 212.467575\n",
            "Batch 12/40 |██████████████████████████████>.....................................................................| 30.00% complete, loss=1.77, accuracy=0 training loss 207.408600\n",
            "Batch 13/40 |████████████████████████████████>...................................................................| 32.50% complete, loss=1.91, accuracy=0 training loss 204.240494\n",
            "Batch 14/40 |███████████████████████████████████>................................................................| 35.00% complete, loss=2.05, accuracy=0 training loss 200.730408\n",
            "Batch 15/40 |█████████████████████████████████████>..............................................................| 37.50% complete, loss=2.19, accuracy=0 training loss 197.039902\n",
            "Batch 16/40 |████████████████████████████████████████>...........................................................| 40.00% complete, loss=2.33, accuracy=0 training loss 192.843811\n",
            "Batch 17/40 |██████████████████████████████████████████>.........................................................| 42.50% complete, loss=2.46, accuracy=0 training loss 190.127563\n",
            "Batch 18/40 |█████████████████████████████████████████████>......................................................| 45.00% complete, loss=2.60, accuracy=0 training loss 186.134079\n",
            "Batch 19/40 |███████████████████████████████████████████████>....................................................| 47.50% complete, loss=2.73, accuracy=0 training loss 182.542374\n",
            "Batch 20/40 |██████████████████████████████████████████████████>.................................................| 50.00% complete, loss=2.85, accuracy=0 training loss 180.040375\n",
            "Batch 21/40 |████████████████████████████████████████████████████>...............................................| 52.50% complete, loss=2.98, accuracy=0 training loss 176.991989\n",
            "Batch 22/40 |███████████████████████████████████████████████████████>............................................| 55.00% complete, loss=3.10, accuracy=0 training loss 174.116043\n",
            "Batch 23/40 |█████████████████████████████████████████████████████████>..........................................| 57.50% complete, loss=3.22, accuracy=0 training loss 170.424652\n",
            "Batch 24/40 |████████████████████████████████████████████████████████████>.......................................| 60.00% complete, loss=3.34, accuracy=0 training loss 167.572617\n",
            "Batch 25/40 |██████████████████████████████████████████████████████████████>.....................................| 62.50% complete, loss=3.46, accuracy=0 training loss 165.003616\n",
            "Batch 26/40 |█████████████████████████████████████████████████████████████████>..................................| 65.00% complete, loss=3.57, accuracy=0 training loss 162.359238\n",
            "Batch 27/40 |███████████████████████████████████████████████████████████████████>................................| 67.50% complete, loss=3.68, accuracy=0 training loss 159.263519\n",
            "Batch 28/40 |██████████████████████████████████████████████████████████████████████>.............................| 70.00% complete, loss=3.79, accuracy=0 training loss 157.259735\n",
            "Batch 29/40 |████████████████████████████████████████████████████████████████████████>...........................| 72.50% complete, loss=3.90, accuracy=0 training loss 154.716797\n",
            "Batch 30/40 |███████████████████████████████████████████████████████████████████████████>........................| 75.00% complete, loss=4.01, accuracy=0 training loss 151.681061\n",
            "Batch 31/40 |█████████████████████████████████████████████████████████████████████████████>......................| 77.50% complete, loss=4.12, accuracy=0 training loss 149.282608\n",
            "Batch 32/40 |████████████████████████████████████████████████████████████████████████████████>...................| 80.00% complete, loss=4.22, accuracy=0 training loss 146.753067\n",
            "Batch 33/40 |██████████████████████████████████████████████████████████████████████████████████>.................| 82.50% complete, loss=4.32, accuracy=0 training loss 143.839096\n",
            "Batch 34/40 |█████████████████████████████████████████████████████████████████████████████████████>..............| 85.00% complete, loss=4.42, accuracy=0 training loss 141.290512\n",
            "Batch 35/40 |███████████████████████████████████████████████████████████████████████████████████████>............| 87.50% complete, loss=4.52, accuracy=0 training loss 139.346542\n",
            "Batch 36/40 |██████████████████████████████████████████████████████████████████████████████████████████>.........| 90.00% complete, loss=4.62, accuracy=0 training loss 137.224930\n",
            "Batch 37/40 |████████████████████████████████████████████████████████████████████████████████████████████>.......| 92.50% complete, loss=4.71, accuracy=0 training loss 135.066772\n",
            "Batch 38/40 |███████████████████████████████████████████████████████████████████████████████████████████████>....| 95.00% complete, loss=4.81, accuracy=0 training loss 131.671478\n",
            "Batch 39/40 |█████████████████████████████████████████████████████████████████████████████████████████████████>..| 97.50% complete, loss=4.90, accuracy=0 training loss 130.042160\n",
            "Batch 40/40 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=4.99, accuracy=0 training loss 127.287346\n",
            "\n",
            "\n",
            "Evaluating...\n",
            "Batch 1/8 |████████████>.......................................................................................| 12.50% complete, loss=0.00, accuracy=0 validation loss 120.410118\n",
            "Batch 2/8 |█████████████████████████>..........................................................................| 25.00% complete, loss=0.42, accuracy=0 validation loss 121.091080\n",
            "Batch 3/8 |█████████████████████████████████████>..............................................................| 37.50% complete, loss=0.84, accuracy=0 validation loss 121.202873\n",
            "Batch 4/8 |██████████████████████████████████████████████████>.................................................| 50.00% complete, loss=1.26, accuracy=0 validation loss 121.118057\n",
            "Batch 5/8 |██████████████████████████████████████████████████████████████>.....................................| 62.50% complete, loss=1.68, accuracy=0 validation loss 120.429588\n",
            "Batch 6/8 |███████████████████████████████████████████████████████████████████████████>........................| 75.00% complete, loss=2.10, accuracy=0 validation loss 121.160866\n",
            "Batch 7/8 |███████████████████████████████████████████████████████████████████████████████████████>............| 87.50% complete, loss=2.52, accuracy=0 validation loss 120.033203\n",
            "Batch 8/8 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=2.94, accuracy=0 validation loss 120.835091\n",
            "\n",
            "\n",
            "Training Loss: 5.076\n",
            "Validation Loss: 3.355\n",
            "\n",
            "Epoch 2 / 6:\n",
            "Batch 1/40 |██>.................................................................................................| 2.50% complete, loss=0.00, accuracy=0 training loss 124.899445\n",
            "Batch 2/40 |█████>..............................................................................................| 5.00% complete, loss=0.09, accuracy=0 training loss 122.952255\n",
            "Batch 3/40 |███████>............................................................................................| 7.50% complete, loss=0.17, accuracy=0 training loss 120.242584\n",
            "Batch 4/40 |██████████>.........................................................................................| 10.00% complete, loss=0.26, accuracy=0 training loss 118.065742\n",
            "Batch 5/40 |████████████>.......................................................................................| 12.50% complete, loss=0.34, accuracy=0 training loss 115.939728\n",
            "Batch 6/40 |███████████████>....................................................................................| 15.00% complete, loss=0.42, accuracy=0 training loss 113.619888\n",
            "Batch 7/40 |█████████████████>..................................................................................| 17.50% complete, loss=0.50, accuracy=0 training loss 111.468765\n",
            "Batch 8/40 |████████████████████>...............................................................................| 20.00% complete, loss=0.57, accuracy=0 training loss 109.636650\n",
            "Batch 9/40 |██████████████████████>.............................................................................| 22.50% complete, loss=0.65, accuracy=0 training loss 106.075935\n",
            "Batch 10/40 |█████████████████████████>..........................................................................| 25.00% complete, loss=0.72, accuracy=0 training loss 103.708870\n",
            "Batch 11/40 |███████████████████████████>........................................................................| 27.50% complete, loss=0.80, accuracy=0 training loss 102.332802\n",
            "Batch 12/40 |██████████████████████████████>.....................................................................| 30.00% complete, loss=0.87, accuracy=0 training loss 99.225327\n",
            "Batch 13/40 |████████████████████████████████>...................................................................| 32.50% complete, loss=0.94, accuracy=0 training loss 97.498642\n",
            "Batch 14/40 |███████████████████████████████████>................................................................| 35.00% complete, loss=1.00, accuracy=0 training loss 95.416130\n",
            "Batch 15/40 |█████████████████████████████████████>..............................................................| 37.50% complete, loss=1.07, accuracy=0 training loss 92.729996\n",
            "Batch 16/40 |████████████████████████████████████████>...........................................................| 40.00% complete, loss=1.13, accuracy=0 training loss 90.989609\n",
            "Batch 17/40 |██████████████████████████████████████████>.........................................................| 42.50% complete, loss=1.20, accuracy=0 training loss 87.731750\n",
            "Batch 18/40 |█████████████████████████████████████████████>......................................................| 45.00% complete, loss=1.26, accuracy=0 training loss 85.842705\n",
            "Batch 19/40 |███████████████████████████████████████████████>....................................................| 47.50% complete, loss=1.32, accuracy=0 training loss 83.388382\n",
            "Batch 20/40 |██████████████████████████████████████████████████>.................................................| 50.00% complete, loss=1.38, accuracy=0 training loss 81.570366\n",
            "Batch 21/40 |████████████████████████████████████████████████████>...............................................| 52.50% complete, loss=1.43, accuracy=0 training loss 78.836815\n",
            "Batch 22/40 |███████████████████████████████████████████████████████>............................................| 55.00% complete, loss=1.49, accuracy=0 training loss 77.078270\n",
            "Batch 23/40 |█████████████████████████████████████████████████████████>..........................................| 57.50% complete, loss=1.54, accuracy=0 training loss 74.340843\n",
            "Batch 24/40 |████████████████████████████████████████████████████████████>.......................................| 60.00% complete, loss=1.59, accuracy=0 training loss 72.267815\n",
            "Batch 25/40 |██████████████████████████████████████████████████████████████>.....................................| 62.50% complete, loss=1.64, accuracy=0 training loss 69.465622\n",
            "Batch 26/40 |█████████████████████████████████████████████████████████████████>..................................| 65.00% complete, loss=1.69, accuracy=0 training loss 67.740387\n",
            "Batch 27/40 |███████████████████████████████████████████████████████████████████>................................| 67.50% complete, loss=1.74, accuracy=0 training loss 65.014252\n",
            "Batch 28/40 |██████████████████████████████████████████████████████████████████████>.............................| 70.00% complete, loss=1.78, accuracy=0 training loss 63.011589\n",
            "Batch 29/40 |████████████████████████████████████████████████████████████████████████>...........................| 72.50% complete, loss=1.83, accuracy=0 training loss 59.803352\n",
            "Batch 30/40 |███████████████████████████████████████████████████████████████████████████>........................| 75.00% complete, loss=1.87, accuracy=0 training loss 58.078236\n",
            "Batch 31/40 |█████████████████████████████████████████████████████████████████████████████>......................| 77.50% complete, loss=1.91, accuracy=0 training loss 55.535709\n",
            "Batch 32/40 |████████████████████████████████████████████████████████████████████████████████>...................| 80.00% complete, loss=1.95, accuracy=0 training loss 53.283260\n",
            "Batch 33/40 |██████████████████████████████████████████████████████████████████████████████████>.................| 82.50% complete, loss=1.98, accuracy=0 training loss 51.065582\n",
            "Batch 34/40 |█████████████████████████████████████████████████████████████████████████████████████>..............| 85.00% complete, loss=2.02, accuracy=0 training loss 48.303509\n",
            "Batch 35/40 |███████████████████████████████████████████████████████████████████████████████████████>............| 87.50% complete, loss=2.05, accuracy=0 training loss 46.882607\n",
            "Batch 36/40 |██████████████████████████████████████████████████████████████████████████████████████████>.........| 90.00% complete, loss=2.09, accuracy=0 training loss 43.744080\n",
            "Batch 37/40 |████████████████████████████████████████████████████████████████████████████████████████████>.......| 92.50% complete, loss=2.12, accuracy=0 training loss 40.957966\n",
            "Batch 38/40 |███████████████████████████████████████████████████████████████████████████████████████████████>....| 95.00% complete, loss=2.14, accuracy=0 training loss 38.774162\n",
            "Batch 39/40 |█████████████████████████████████████████████████████████████████████████████████████████████████>..| 97.50% complete, loss=2.17, accuracy=0 training loss 36.615898\n",
            "Batch 40/40 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=2.20, accuracy=0 training loss 34.569950\n",
            "\n",
            "\n",
            "Evaluating...\n",
            "Batch 1/8 |████████████>.......................................................................................| 12.50% complete, loss=0.00, accuracy=0 validation loss 25.758589\n",
            "Batch 2/8 |█████████████████████████>..........................................................................| 25.00% complete, loss=0.09, accuracy=0 validation loss 26.526922\n",
            "Batch 3/8 |█████████████████████████████████████>..............................................................| 37.50% complete, loss=0.18, accuracy=0 validation loss 26.525459\n",
            "Batch 4/8 |██████████████████████████████████████████████████>.................................................| 50.00% complete, loss=0.27, accuracy=0 validation loss 26.936550\n",
            "Batch 5/8 |██████████████████████████████████████████████████████████████>.....................................| 62.50% complete, loss=0.37, accuracy=0 validation loss 25.790960\n",
            "Batch 6/8 |███████████████████████████████████████████████████████████████████████████>........................| 75.00% complete, loss=0.46, accuracy=0 validation loss 26.663006\n",
            "Batch 7/8 |███████████████████████████████████████████████████████████████████████████████████████>............| 87.50% complete, loss=0.55, accuracy=0 validation loss 25.306631\n",
            "Batch 8/8 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.64, accuracy=0 validation loss 26.217047\n",
            "\n",
            "\n",
            "Training Loss: 2.221\n",
            "Validation Loss: 0.728\n",
            "\n",
            "Epoch 3 / 6:\n",
            "Batch 1/40 |██>.................................................................................................| 2.50% complete, loss=0.00, accuracy=0 training loss 31.650866\n",
            "Batch 2/40 |█████>..............................................................................................| 5.00% complete, loss=0.02, accuracy=0 training loss 28.892155\n",
            "Batch 3/40 |███████>............................................................................................| 7.50% complete, loss=0.04, accuracy=0 training loss 27.044729\n",
            "Batch 4/40 |██████████>.........................................................................................| 10.00% complete, loss=0.06, accuracy=0 training loss 24.239872\n",
            "Batch 5/40 |████████████>.......................................................................................| 12.50% complete, loss=0.08, accuracy=0 training loss 21.812738\n",
            "Batch 6/40 |███████████████>....................................................................................| 15.00% complete, loss=0.09, accuracy=0 training loss 19.375092\n",
            "Batch 7/40 |█████████████████>..................................................................................| 17.50% complete, loss=0.11, accuracy=0 training loss 17.403244\n",
            "Batch 8/40 |████████████████████>...............................................................................| 20.00% complete, loss=0.12, accuracy=0 training loss 15.438381\n",
            "Batch 9/40 |██████████████████████>.............................................................................| 22.50% complete, loss=0.13, accuracy=0 training loss 13.889853\n",
            "Batch 10/40 |█████████████████████████>..........................................................................| 25.00% complete, loss=0.14, accuracy=0 training loss 12.029627\n",
            "Batch 11/40 |███████████████████████████>........................................................................| 27.50% complete, loss=0.15, accuracy=0 training loss 10.440708\n",
            "Batch 12/40 |██████████████████████████████>.....................................................................| 30.00% complete, loss=0.15, accuracy=0 training loss 8.648197\n",
            "Batch 13/40 |████████████████████████████████>...................................................................| 32.50% complete, loss=0.16, accuracy=0 training loss 6.572174\n",
            "Batch 14/40 |███████████████████████████████████>................................................................| 35.00% complete, loss=0.16, accuracy=0 training loss 4.655394\n",
            "Batch 15/40 |█████████████████████████████████████>..............................................................| 37.50% complete, loss=0.17, accuracy=0 training loss 2.775801\n",
            "Batch 16/40 |████████████████████████████████████████>...........................................................| 40.00% complete, loss=0.17, accuracy=0 training loss 1.031842\n",
            "Batch 17/40 |██████████████████████████████████████████>.........................................................| 42.50% complete, loss=0.17, accuracy=0 training loss -0.763672\n",
            "Batch 18/40 |█████████████████████████████████████████████>......................................................| 45.00% complete, loss=0.17, accuracy=0 training loss -1.509786\n",
            "Batch 19/40 |███████████████████████████████████████████████>....................................................| 47.50% complete, loss=0.17, accuracy=0 training loss -2.057387\n",
            "Batch 20/40 |██████████████████████████████████████████████████>.................................................| 50.00% complete, loss=0.17, accuracy=0 training loss -2.070372\n",
            "Batch 21/40 |████████████████████████████████████████████████████>...............................................| 52.50% complete, loss=0.17, accuracy=0 training loss -2.069674\n",
            "Batch 22/40 |███████████████████████████████████████████████████████>............................................| 55.00% complete, loss=0.16, accuracy=0 training loss -2.069235\n",
            "Batch 23/40 |█████████████████████████████████████████████████████████>..........................................| 57.50% complete, loss=0.16, accuracy=0 training loss -2.069026\n",
            "Batch 24/40 |████████████████████████████████████████████████████████████>.......................................| 60.00% complete, loss=0.16, accuracy=0 training loss -2.069020\n",
            "Batch 25/40 |██████████████████████████████████████████████████████████████>.....................................| 62.50% complete, loss=0.16, accuracy=0 training loss -2.069193\n",
            "Batch 26/40 |█████████████████████████████████████████████████████████████████>..................................| 65.00% complete, loss=0.16, accuracy=0 training loss -2.037876\n",
            "Batch 27/40 |███████████████████████████████████████████████████████████████████>................................| 67.50% complete, loss=0.16, accuracy=0 training loss -2.069763\n",
            "Batch 28/40 |██████████████████████████████████████████████████████████████████████>.............................| 70.00% complete, loss=0.16, accuracy=0 training loss -2.070149\n",
            "Batch 29/40 |████████████████████████████████████████████████████████████████████████>...........................| 72.50% complete, loss=0.15, accuracy=0 training loss -2.070673\n",
            "Batch 30/40 |███████████████████████████████████████████████████████████████████████████>........................| 75.00% complete, loss=0.15, accuracy=0 training loss -2.071317\n",
            "Batch 31/40 |█████████████████████████████████████████████████████████████████████████████>......................| 77.50% complete, loss=0.15, accuracy=0 training loss -2.047990\n",
            "Batch 32/40 |████████████████████████████████████████████████████████████████████████████████>...................| 80.00% complete, loss=0.15, accuracy=0 training loss -2.072710\n",
            "Batch 33/40 |██████████████████████████████████████████████████████████████████████████████████>.................| 82.50% complete, loss=0.15, accuracy=0 training loss -2.073456\n",
            "Batch 34/40 |█████████████████████████████████████████████████████████████████████████████████████>..............| 85.00% complete, loss=0.15, accuracy=0 training loss -2.074297\n",
            "Batch 35/40 |███████████████████████████████████████████████████████████████████████████████████████>............| 87.50% complete, loss=0.15, accuracy=0 training loss -2.075228\n",
            "Batch 36/40 |██████████████████████████████████████████████████████████████████████████████████████████>.........| 90.00% complete, loss=0.14, accuracy=0 training loss -2.076236\n",
            "Batch 37/40 |████████████████████████████████████████████████████████████████████████████████████████████>.......| 92.50% complete, loss=0.14, accuracy=0 training loss -2.077312\n",
            "Batch 38/40 |███████████████████████████████████████████████████████████████████████████████████████████████>....| 95.00% complete, loss=0.14, accuracy=0 training loss -2.078450\n",
            "Batch 39/40 |█████████████████████████████████████████████████████████████████████████████████████████████████>..| 97.50% complete, loss=0.14, accuracy=0 training loss -2.079642\n",
            "Batch 40/40 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=0.14, accuracy=0 training loss -2.080883\n",
            "\n",
            "\n",
            "Evaluating...\n",
            "Batch 1/8 |████████████>.......................................................................................| 12.50% complete, loss=0.00, accuracy=0 validation loss -2.082167\n",
            "Batch 2/8 |█████████████████████████>..........................................................................| 25.00% complete, loss=-0.01, accuracy=0 validation loss -2.082167\n",
            "Batch 3/8 |█████████████████████████████████████>..............................................................| 37.50% complete, loss=-0.01, accuracy=0 validation loss -2.082167\n",
            "Batch 4/8 |██████████████████████████████████████████████████>.................................................| 50.00% complete, loss=-0.02, accuracy=0 validation loss -2.082167\n",
            "Batch 5/8 |██████████████████████████████████████████████████████████████>.....................................| 62.50% complete, loss=-0.03, accuracy=0 validation loss -2.082167\n",
            "Batch 6/8 |███████████████████████████████████████████████████████████████████████████>........................| 75.00% complete, loss=-0.04, accuracy=0 validation loss -2.082167\n",
            "Batch 7/8 |███████████████████████████████████████████████████████████████████████████████████████>............| 87.50% complete, loss=-0.04, accuracy=0 validation loss -2.082167\n",
            "Batch 8/8 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=-0.05, accuracy=0 validation loss -2.082167\n",
            "\n",
            "\n",
            "Training Loss: 0.138\n",
            "Validation Loss: -0.058\n",
            "\n",
            "Epoch 4 / 6:\n",
            "Batch 1/40 |██>.................................................................................................| 2.50% complete, loss=0.00, accuracy=0 training loss -2.082167\n",
            "Batch 2/40 |█████>..............................................................................................| 5.00% complete, loss=-0.00, accuracy=0 training loss -2.083491\n",
            "Batch 3/40 |███████>............................................................................................| 7.50% complete, loss=-0.00, accuracy=0 training loss -2.084850\n",
            "Batch 4/40 |██████████>.........................................................................................| 10.00% complete, loss=-0.00, accuracy=0 training loss -2.086237\n",
            "Batch 5/40 |████████████>.......................................................................................| 12.50% complete, loss=-0.01, accuracy=0 training loss -1.850102\n",
            "Batch 6/40 |███████████████>....................................................................................| 15.00% complete, loss=-0.01, accuracy=0 training loss -2.088879\n",
            "Batch 7/40 |█████████████████>..................................................................................| 17.50% complete, loss=-0.01, accuracy=0 training loss -2.090147\n",
            "Batch 8/40 |████████████████████>...............................................................................| 20.00% complete, loss=-0.01, accuracy=0 training loss -2.091457\n",
            "Batch 9/40 |██████████████████████>.............................................................................| 22.50% complete, loss=-0.01, accuracy=0 training loss -2.092799\n",
            "Batch 10/40 |█████████████████████████>..........................................................................| 25.00% complete, loss=-0.01, accuracy=0 training loss -2.094174\n",
            "Batch 11/40 |███████████████████████████>........................................................................| 27.50% complete, loss=-0.01, accuracy=0 training loss -2.095577\n",
            "Batch 12/40 |██████████████████████████████>.....................................................................| 30.00% complete, loss=-0.02, accuracy=0 training loss -2.097006\n",
            "Batch 13/40 |████████████████████████████████>...................................................................| 32.50% complete, loss=-0.02, accuracy=0 training loss -2.098454\n",
            "Batch 14/40 |███████████████████████████████████>................................................................| 35.00% complete, loss=-0.02, accuracy=0 training loss -2.099924\n",
            "Batch 15/40 |█████████████████████████████████████>..............................................................| 37.50% complete, loss=-0.02, accuracy=0 training loss -2.101410\n",
            "Batch 16/40 |████████████████████████████████████████>...........................................................| 40.00% complete, loss=-0.02, accuracy=0 training loss -2.102914\n",
            "Batch 17/40 |██████████████████████████████████████████>.........................................................| 42.50% complete, loss=-0.02, accuracy=0 training loss -2.104429\n",
            "Batch 18/40 |█████████████████████████████████████████████>......................................................| 45.00% complete, loss=-0.02, accuracy=0 training loss -2.105959\n",
            "Batch 19/40 |███████████████████████████████████████████████>....................................................| 47.50% complete, loss=-0.03, accuracy=0 training loss -2.107498\n",
            "Batch 20/40 |██████████████████████████████████████████████████>.................................................| 50.00% complete, loss=-0.03, accuracy=0 training loss -2.109047\n",
            "Batch 21/40 |████████████████████████████████████████████████████>...............................................| 52.50% complete, loss=-0.03, accuracy=0 training loss -2.110603\n",
            "Batch 22/40 |███████████████████████████████████████████████████████>............................................| 55.00% complete, loss=-0.03, accuracy=0 training loss -2.112169\n",
            "Batch 23/40 |█████████████████████████████████████████████████████████>..........................................| 57.50% complete, loss=-0.03, accuracy=0 training loss -2.099376\n",
            "Batch 24/40 |████████████████████████████████████████████████████████████>.......................................| 60.00% complete, loss=-0.03, accuracy=0 training loss -2.115113\n",
            "Batch 25/40 |██████████████████████████████████████████████████████████████>.....................................| 62.50% complete, loss=-0.03, accuracy=0 training loss -2.116512\n",
            "Batch 26/40 |█████████████████████████████████████████████████████████████████>..................................| 65.00% complete, loss=-0.04, accuracy=0 training loss -2.117932\n",
            "Batch 27/40 |███████████████████████████████████████████████████████████████████>................................| 67.50% complete, loss=-0.04, accuracy=0 training loss -2.119374\n",
            "Batch 28/40 |██████████████████████████████████████████████████████████████████████>.............................| 70.00% complete, loss=-0.04, accuracy=0 training loss -2.120834\n",
            "Batch 29/40 |████████████████████████████████████████████████████████████████████████>...........................| 72.50% complete, loss=-0.04, accuracy=0 training loss -2.122311\n",
            "Batch 30/40 |███████████████████████████████████████████████████████████████████████████>........................| 75.00% complete, loss=-0.04, accuracy=0 training loss -2.123803\n",
            "Batch 31/40 |█████████████████████████████████████████████████████████████████████████████>......................| 77.50% complete, loss=-0.04, accuracy=0 training loss -2.125307\n",
            "Batch 32/40 |████████████████████████████████████████████████████████████████████████████████>...................| 80.00% complete, loss=-0.05, accuracy=0 training loss -2.126824\n",
            "Batch 33/40 |██████████████████████████████████████████████████████████████████████████████████>.................| 82.50% complete, loss=-0.05, accuracy=0 training loss -2.128351\n",
            "Batch 34/40 |█████████████████████████████████████████████████████████████████████████████████████>..............| 85.00% complete, loss=-0.05, accuracy=0 training loss -2.129888\n",
            "Batch 35/40 |███████████████████████████████████████████████████████████████████████████████████████>............| 87.50% complete, loss=-0.05, accuracy=0 training loss -2.131431\n",
            "Batch 36/40 |██████████████████████████████████████████████████████████████████████████████████████████>.........| 90.00% complete, loss=-0.05, accuracy=0 training loss -2.132984\n",
            "Batch 37/40 |████████████████████████████████████████████████████████████████████████████████████████████>.......| 92.50% complete, loss=-0.05, accuracy=0 training loss -2.134543\n",
            "Batch 38/40 |███████████████████████████████████████████████████████████████████████████████████████████████>....| 95.00% complete, loss=-0.05, accuracy=0 training loss -2.136106\n",
            "Batch 39/40 |█████████████████████████████████████████████████████████████████████████████████████████████████>..| 97.50% complete, loss=-0.06, accuracy=0 training loss -2.137676\n",
            "Batch 40/40 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=-0.06, accuracy=0 training loss -2.139252\n",
            "\n",
            "\n",
            "Evaluating...\n",
            "Batch 1/8 |████████████>.......................................................................................| 12.50% complete, loss=0.00, accuracy=0 validation loss -2.140829\n",
            "Batch 2/8 |█████████████████████████>..........................................................................| 25.00% complete, loss=-0.01, accuracy=0 validation loss -2.140829\n",
            "Batch 3/8 |█████████████████████████████████████>..............................................................| 37.50% complete, loss=-0.01, accuracy=0 validation loss -2.140829\n",
            "Batch 4/8 |██████████████████████████████████████████████████>.................................................| 50.00% complete, loss=-0.02, accuracy=0 validation loss -2.140829\n",
            "Batch 5/8 |██████████████████████████████████████████████████████████████>.....................................| 62.50% complete, loss=-0.03, accuracy=0 validation loss -2.140829\n",
            "Batch 6/8 |███████████████████████████████████████████████████████████████████████████>........................| 75.00% complete, loss=-0.04, accuracy=0 validation loss -2.140829\n",
            "Batch 7/8 |███████████████████████████████████████████████████████████████████████████████████████>............| 87.50% complete, loss=-0.04, accuracy=0 validation loss -2.140829\n",
            "Batch 8/8 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=-0.05, accuracy=0 validation loss -2.140829\n",
            "\n",
            "\n",
            "Training Loss: -0.058\n",
            "Validation Loss: -0.059\n",
            "\n",
            "Epoch 5 / 6:\n",
            "Batch 1/40 |██>.................................................................................................| 2.50% complete, loss=0.00, accuracy=0 training loss -2.140829\n",
            "Batch 2/40 |█████>..............................................................................................| 5.00% complete, loss=-0.00, accuracy=0 training loss -2.142411\n",
            "Batch 3/40 |███████>............................................................................................| 7.50% complete, loss=-0.00, accuracy=0 training loss -2.143996\n",
            "Batch 4/40 |██████████>.........................................................................................| 10.00% complete, loss=-0.00, accuracy=0 training loss -2.145583\n",
            "Batch 5/40 |████████████>.......................................................................................| 12.50% complete, loss=-0.01, accuracy=0 training loss -2.147174\n",
            "Batch 6/40 |███████████████>....................................................................................| 15.00% complete, loss=-0.01, accuracy=0 training loss -2.148766\n",
            "Batch 7/40 |█████████████████>..................................................................................| 17.50% complete, loss=-0.01, accuracy=0 training loss -2.150361\n",
            "Batch 8/40 |████████████████████>...............................................................................| 20.00% complete, loss=-0.01, accuracy=0 training loss -2.151958\n",
            "Batch 9/40 |██████████████████████>.............................................................................| 22.50% complete, loss=-0.01, accuracy=0 training loss -2.153554\n",
            "Batch 10/40 |█████████████████████████>..........................................................................| 25.00% complete, loss=-0.01, accuracy=0 training loss -2.155153\n",
            "Batch 11/40 |███████████████████████████>........................................................................| 27.50% complete, loss=-0.01, accuracy=0 training loss -2.156753\n",
            "Batch 12/40 |██████████████████████████████>.....................................................................| 30.00% complete, loss=-0.02, accuracy=0 training loss -2.158354\n",
            "Batch 13/40 |████████████████████████████████>...................................................................| 32.50% complete, loss=-0.02, accuracy=0 training loss -2.159956\n",
            "Batch 14/40 |███████████████████████████████████>................................................................| 35.00% complete, loss=-0.02, accuracy=0 training loss -2.161559\n",
            "Batch 15/40 |█████████████████████████████████████>..............................................................| 37.50% complete, loss=-0.02, accuracy=0 training loss -2.163160\n",
            "Batch 16/40 |████████████████████████████████████████>...........................................................| 40.00% complete, loss=-0.02, accuracy=0 training loss -2.164765\n",
            "Batch 17/40 |██████████████████████████████████████████>.........................................................| 42.50% complete, loss=-0.02, accuracy=0 training loss -2.166370\n",
            "Batch 18/40 |█████████████████████████████████████████████>......................................................| 45.00% complete, loss=-0.03, accuracy=0 training loss -2.167973\n",
            "Batch 19/40 |███████████████████████████████████████████████>....................................................| 47.50% complete, loss=-0.03, accuracy=0 training loss -2.169578\n",
            "Batch 20/40 |██████████████████████████████████████████████████>.................................................| 50.00% complete, loss=-0.03, accuracy=0 training loss -2.171184\n",
            "Batch 21/40 |████████████████████████████████████████████████████>...............................................| 52.50% complete, loss=-0.03, accuracy=0 training loss -2.172788\n",
            "Batch 22/40 |███████████████████████████████████████████████████████>............................................| 55.00% complete, loss=-0.03, accuracy=0 training loss -2.174394\n",
            "Batch 23/40 |█████████████████████████████████████████████████████████>..........................................| 57.50% complete, loss=-0.03, accuracy=0 training loss -2.169850\n",
            "Batch 24/40 |████████████████████████████████████████████████████████████>.......................................| 60.00% complete, loss=-0.03, accuracy=0 training loss -2.177393\n",
            "Batch 25/40 |██████████████████████████████████████████████████████████████>.....................................| 62.50% complete, loss=-0.04, accuracy=0 training loss -2.178809\n",
            "Batch 26/40 |█████████████████████████████████████████████████████████████████>..................................| 65.00% complete, loss=-0.04, accuracy=0 training loss -2.180244\n",
            "Batch 27/40 |███████████████████████████████████████████████████████████████████>................................| 67.50% complete, loss=-0.04, accuracy=0 training loss -2.181695\n",
            "Batch 28/40 |██████████████████████████████████████████████████████████████████████>.............................| 70.00% complete, loss=-0.04, accuracy=0 training loss -2.183163\n",
            "Batch 29/40 |████████████████████████████████████████████████████████████████████████>...........................| 72.50% complete, loss=-0.04, accuracy=0 training loss -2.184643\n",
            "Batch 30/40 |███████████████████████████████████████████████████████████████████████████>........................| 75.00% complete, loss=-0.04, accuracy=0 training loss -2.186139\n",
            "Batch 31/40 |█████████████████████████████████████████████████████████████████████████████>......................| 77.50% complete, loss=-0.05, accuracy=0 training loss -2.187642\n",
            "Batch 32/40 |████████████████████████████████████████████████████████████████████████████████>...................| 80.00% complete, loss=-0.05, accuracy=0 training loss -2.189158\n",
            "Batch 33/40 |██████████████████████████████████████████████████████████████████████████████████>.................| 82.50% complete, loss=-0.05, accuracy=0 training loss -2.190683\n",
            "Batch 34/40 |█████████████████████████████████████████████████████████████████████████████████████>..............| 85.00% complete, loss=-0.05, accuracy=0 training loss -2.192215\n",
            "Batch 35/40 |███████████████████████████████████████████████████████████████████████████████████████>............| 87.50% complete, loss=-0.05, accuracy=0 training loss -2.193755\n",
            "Batch 36/40 |██████████████████████████████████████████████████████████████████████████████████████████>.........| 90.00% complete, loss=-0.05, accuracy=0 training loss -2.195303\n",
            "Batch 37/40 |████████████████████████████████████████████████████████████████████████████████████████████>.......| 92.50% complete, loss=-0.05, accuracy=0 training loss -2.196856\n",
            "Batch 38/40 |███████████████████████████████████████████████████████████████████████████████████████████████>....| 95.00% complete, loss=-0.06, accuracy=0 training loss -2.198414\n",
            "Batch 39/40 |█████████████████████████████████████████████████████████████████████████████████████████████████>..| 97.50% complete, loss=-0.06, accuracy=0 training loss -2.199977\n",
            "Batch 40/40 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=-0.06, accuracy=0 training loss -2.201545\n",
            "\n",
            "\n",
            "Evaluating...\n",
            "Batch 1/8 |████████████>.......................................................................................| 12.50% complete, loss=0.00, accuracy=0 validation loss -2.203117\n",
            "Batch 2/8 |█████████████████████████>..........................................................................| 25.00% complete, loss=-0.01, accuracy=0 validation loss -2.203117\n",
            "Batch 3/8 |█████████████████████████████████████>..............................................................| 37.50% complete, loss=-0.02, accuracy=0 validation loss -2.203117\n",
            "Batch 4/8 |██████████████████████████████████████████████████>.................................................| 50.00% complete, loss=-0.02, accuracy=0 validation loss -2.203117\n",
            "Batch 5/8 |██████████████████████████████████████████████████████████████>.....................................| 62.50% complete, loss=-0.03, accuracy=0 validation loss -2.203117\n",
            "Batch 6/8 |███████████████████████████████████████████████████████████████████████████>........................| 75.00% complete, loss=-0.04, accuracy=0 validation loss -2.203117\n",
            "Batch 7/8 |███████████████████████████████████████████████████████████████████████████████████████>............| 87.50% complete, loss=-0.05, accuracy=0 validation loss -2.203117\n",
            "Batch 8/8 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=-0.05, accuracy=0 validation loss -2.203117\n",
            "\n",
            "\n",
            "Training Loss: -0.060\n",
            "Validation Loss: -0.061\n",
            "\n",
            "Epoch 6 / 6:\n",
            "Batch 1/40 |██>.................................................................................................| 2.50% complete, loss=0.00, accuracy=0 training loss -2.200971\n",
            "Batch 2/40 |█████>..............................................................................................| 5.00% complete, loss=-0.00, accuracy=0 training loss -2.204490\n",
            "Batch 3/40 |███████>............................................................................................| 7.50% complete, loss=-0.00, accuracy=0 training loss -2.205888\n",
            "Batch 4/40 |██████████>.........................................................................................| 10.00% complete, loss=-0.00, accuracy=0 training loss -2.207308\n",
            "Batch 5/40 |████████████>.......................................................................................| 12.50% complete, loss=-0.01, accuracy=0 training loss -2.208744\n",
            "Batch 6/40 |███████████████>....................................................................................| 15.00% complete, loss=-0.01, accuracy=0 training loss -2.210199\n",
            "Batch 7/40 |█████████████████>..................................................................................| 17.50% complete, loss=-0.01, accuracy=0 training loss -2.211670\n",
            "Batch 8/40 |████████████████████>...............................................................................| 20.00% complete, loss=-0.01, accuracy=0 training loss -2.213154\n",
            "Batch 9/40 |██████████████████████>.............................................................................| 22.50% complete, loss=-0.01, accuracy=0 training loss -2.214651\n",
            "Batch 10/40 |█████████████████████████>..........................................................................| 25.00% complete, loss=-0.01, accuracy=0 training loss -2.216158\n",
            "Batch 11/40 |███████████████████████████>........................................................................| 27.50% complete, loss=-0.02, accuracy=0 training loss -2.217677\n",
            "Batch 12/40 |██████████████████████████████>.....................................................................| 30.00% complete, loss=-0.02, accuracy=0 training loss -2.219205\n",
            "Batch 13/40 |████████████████████████████████>...................................................................| 32.50% complete, loss=-0.02, accuracy=0 training loss -2.220740\n",
            "Batch 14/40 |███████████████████████████████████>................................................................| 35.00% complete, loss=-0.02, accuracy=0 training loss -2.222285\n",
            "Batch 15/40 |█████████████████████████████████████>..............................................................| 37.50% complete, loss=-0.02, accuracy=0 training loss -2.223834\n",
            "Batch 16/40 |████████████████████████████████████████>...........................................................| 40.00% complete, loss=-0.02, accuracy=0 training loss -2.225390\n",
            "Batch 17/40 |██████████████████████████████████████████>.........................................................| 42.50% complete, loss=-0.02, accuracy=0 training loss -2.226952\n",
            "Batch 18/40 |█████████████████████████████████████████████>......................................................| 45.00% complete, loss=-0.03, accuracy=0 training loss -2.228520\n",
            "Batch 19/40 |███████████████████████████████████████████████>....................................................| 47.50% complete, loss=-0.03, accuracy=0 training loss -2.230091\n",
            "Batch 20/40 |██████████████████████████████████████████████████>.................................................| 50.00% complete, loss=-0.03, accuracy=0 training loss -2.207198\n",
            "Batch 21/40 |████████████████████████████████████████████████████>...............................................| 52.50% complete, loss=-0.03, accuracy=0 training loss -2.233007\n",
            "Batch 22/40 |███████████████████████████████████████████████████████>............................................| 55.00% complete, loss=-0.03, accuracy=0 training loss -2.234376\n",
            "Batch 23/40 |█████████████████████████████████████████████████████████>..........................................| 57.50% complete, loss=-0.03, accuracy=0 training loss -2.235768\n",
            "Batch 24/40 |████████████████████████████████████████████████████████████>.......................................| 60.00% complete, loss=-0.04, accuracy=0 training loss -2.237181\n",
            "Batch 25/40 |██████████████████████████████████████████████████████████████>.....................................| 62.50% complete, loss=-0.04, accuracy=0 training loss -2.238616\n",
            "Batch 26/40 |█████████████████████████████████████████████████████████████████>..................................| 65.00% complete, loss=-0.04, accuracy=0 training loss -2.240070\n",
            "Batch 27/40 |███████████████████████████████████████████████████████████████████>................................| 67.50% complete, loss=-0.04, accuracy=0 training loss -2.241536\n",
            "Batch 28/40 |██████████████████████████████████████████████████████████████████████>.............................| 70.00% complete, loss=-0.04, accuracy=0 training loss -2.243021\n",
            "Batch 29/40 |████████████████████████████████████████████████████████████████████████>...........................| 72.50% complete, loss=-0.04, accuracy=0 training loss -2.244517\n",
            "Batch 30/40 |███████████████████████████████████████████████████████████████████████████>........................| 75.00% complete, loss=-0.04, accuracy=0 training loss -2.246025\n",
            "Batch 31/40 |█████████████████████████████████████████████████████████████████████████████>......................| 77.50% complete, loss=-0.05, accuracy=0 training loss -2.247543\n",
            "Batch 32/40 |████████████████████████████████████████████████████████████████████████████████>...................| 80.00% complete, loss=-0.05, accuracy=0 training loss -2.249072\n",
            "Batch 33/40 |██████████████████████████████████████████████████████████████████████████████████>.................| 82.50% complete, loss=-0.05, accuracy=0 training loss -2.250611\n",
            "Batch 34/40 |█████████████████████████████████████████████████████████████████████████████████████>..............| 85.00% complete, loss=-0.05, accuracy=0 training loss -2.252157\n",
            "Batch 35/40 |███████████████████████████████████████████████████████████████████████████████████████>............| 87.50% complete, loss=-0.05, accuracy=0 training loss -2.253710\n",
            "Batch 36/40 |██████████████████████████████████████████████████████████████████████████████████████████>.........| 90.00% complete, loss=-0.05, accuracy=0 training loss -2.255268\n",
            "Batch 37/40 |████████████████████████████████████████████████████████████████████████████████████████████>.......| 92.50% complete, loss=-0.06, accuracy=0 training loss -2.228081\n",
            "Batch 38/40 |███████████████████████████████████████████████████████████████████████████████████████████████>....| 95.00% complete, loss=-0.06, accuracy=0 training loss -2.258189\n",
            "Batch 39/40 |█████████████████████████████████████████████████████████████████████████████████████████████████>..| 97.50% complete, loss=-0.06, accuracy=0 training loss -2.259570\n",
            "Batch 40/40 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=-0.06, accuracy=0 training loss -2.260975\n",
            "\n",
            "\n",
            "Evaluating...\n",
            "Batch 1/8 |████████████>.......................................................................................| 12.50% complete, loss=0.00, accuracy=0 validation loss -2.262401\n",
            "Batch 2/8 |█████████████████████████>..........................................................................| 25.00% complete, loss=-0.01, accuracy=0 validation loss -2.262401\n",
            "Batch 3/8 |█████████████████████████████████████>..............................................................| 37.50% complete, loss=-0.02, accuracy=0 validation loss -2.262401\n",
            "Batch 4/8 |██████████████████████████████████████████████████>.................................................| 50.00% complete, loss=-0.02, accuracy=0 validation loss -2.262401\n",
            "Batch 5/8 |██████████████████████████████████████████████████████████████>.....................................| 62.50% complete, loss=-0.03, accuracy=0 validation loss -2.262401\n",
            "Batch 6/8 |███████████████████████████████████████████████████████████████████████████>........................| 75.00% complete, loss=-0.04, accuracy=0 validation loss -2.262401\n",
            "Batch 7/8 |███████████████████████████████████████████████████████████████████████████████████████>............| 87.50% complete, loss=-0.05, accuracy=0 validation loss -2.262401\n",
            "Batch 8/8 |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.00% complete, loss=-0.05, accuracy=0 validation loss -2.262401\n",
            "\n",
            "\n",
            "Training Loss: -0.062\n",
            "Validation Loss: -0.063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t4bMiq3dfNRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses,'-o')\n",
        "plt.plot(valid_losses,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Train','Valid'])\n",
        "plt.title('Train vs Valid Losses') \n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "stgYguk4dUTD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "cd72165d-fdc0-450e-b2f1-71593b9a6711"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "with torch.no_grad():\n",
        "    lstm_output,predsTrain,weights,biases,r,output = model(train_seq.to(device), train_mask.to(device))\n",
        "    #preds = model(test_seq, test_mask)\n",
        "    predsTrain = predsTrain.detach().cpu().numpy()\n",
        "predsTrain = np.argmax(predsTrain, axis=1)\n",
        "print('Classification Report-Train')\n",
        "print(classification_report(train_y, predsTrain))\n",
        "\n",
        "with torch.no_grad():\n",
        "    lstm_output,predsValid,weights,biases,r,output = model(val_seq.to(device), val_mask.to(device))\n",
        "    #preds = model(test_seq, test_mask)\n",
        "    predsValid = predsValid.detach().cpu().numpy()\n",
        "predsValid = np.argmax(predsValid, axis=1)\n",
        "print('Classification Report-Valid')\n",
        "print(classification_report(val_y, predsValid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSxsWpSBXJXV",
        "outputId": "7abb6134-fcb4-4a8d-d05c-bb05ceb92b94"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report-Train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.98      0.94      1281\n",
            "           1       0.07      0.01      0.02       143\n",
            "\n",
            "    accuracy                           0.88      1424\n",
            "   macro avg       0.49      0.50      0.48      1424\n",
            "weighted avg       0.82      0.88      0.85      1424\n",
            "\n",
            "Classification Report-Valid\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94       256\n",
            "           1       0.25      0.03      0.06        29\n",
            "\n",
            "    accuracy                           0.89       285\n",
            "   macro avg       0.58      0.51      0.50       285\n",
            "weighted avg       0.83      0.89      0.85       285\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_process(data, labels):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    for sentence in data:\n",
        "        bert_inp = bert_tokenizer.__call__(sentence, max_length=12,\n",
        "                                           padding='max_length', pad_to_max_length=True,\n",
        "                                           truncation=True, return_token_type_ids=False)\n",
        "\n",
        "        input_ids.append(bert_inp['input_ids'])\n",
        "        attention_masks.append(bert_inp['attention_mask'])\n",
        "    #del bert_tokenizer\n",
        "    #gc.collect()\n",
        "    #torch.cuda.empty_cache()\n",
        "    input_ids = np.asarray(input_ids)\n",
        "    attention_masks = np.array(attention_masks)\n",
        "    labels = np.array(labels)\n",
        "    d=np.array(data)\n",
        "    return input_ids, attention_masks, labels,d\n",
        "def read_dataset():\n",
        "    data = pd.read_csv(f\"{data_path}/preProcessed_Davidson_10Hate_forTest.csv\")\n",
        "    #data = data.drop(['count', 'hate_speech', 'offensive_language', 'neither'], axis=1)\n",
        "    #data = data.loc[0:9599,:]\n",
        "    print(len(data))\n",
        "    return data['tweet'].tolist(), data['class']\n",
        "def load_and_process():\n",
        "    data, labels = read_dataset()\n",
        "    num_of_labels = len(labels.unique())\n",
        "    #input_ids, attention_masks, labels = data_process(pre_process_dataset(data), labels)\n",
        "    input_ids, attention_masks, labels,d = data_process(data, labels)\n",
        "    return input_ids, attention_masks, labels,d\n",
        "\n",
        "input_ids, attention_masks, labels,text = load_and_process()\n",
        "df = pd.DataFrame(list(zip(input_ids, attention_masks)), columns=['input_ids', 'attention_masks'])\n",
        "test_seq = torch.tensor(df['input_ids'].tolist())\n",
        "test_mask = torch.tensor(df['attention_masks'].tolist())\n",
        "test_y = torch.tensor(labels.tolist())\n",
        "\n",
        "with torch.no_grad():\n",
        "    lstm_output,predsTest,weights,biases,r,output = model(test_seq.to(device), test_mask.to(device))\n",
        "    #preds = model(test_seq, test_mask)\n",
        "    predsTest = predsTest.detach().cpu().numpy()\n",
        "predsTest = np.argmax(predsTest, axis=1)\n",
        "print('Classification Report- New dataset(50% hate and 50% nonhate) ')\n",
        "print(classification_report(test_y, predsTest))"
      ],
      "metadata": {
        "id": "QqBHPUNqJEc_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7851ec12-a2c6-4e46-bca9-1f612e96b010"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "287\n",
            "Classification Report-Valid\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.99      0.67       144\n",
            "           1       0.00      0.00      0.00       143\n",
            "\n",
            "    accuracy                           0.50       287\n",
            "   macro avg       0.25      0.50      0.33       287\n",
            "weighted avg       0.25      0.50      0.33       287\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
